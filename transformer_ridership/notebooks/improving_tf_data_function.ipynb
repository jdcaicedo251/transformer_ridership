{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ff3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d1fbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 16:25:15.703880: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "import data \n",
    "import losses\n",
    "os.chdir('notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c650fd2",
   "metadata": {},
   "source": [
    "# Infering Station Closure\n",
    "\n",
    "Previously I defined station closure if the station had no transaction in the 15-min period. However this seems to be a very restrictive assumptions. There seems to be some time in which the closure happened an there is still a few amount of transactions. The objective here is to select a less restrictive treshold to signal that a station in close "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ba3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.clean_data('../../data/transactions.parquet')\n",
    "target = target.iloc[:,:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8225a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 5 \n",
    "stations = random.sample(list(target.columns), k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1089d0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of transactions by station\n",
    "fig, axs = plt.subplots(10,2, sharey = True, figsize = (15,50))\n",
    "\n",
    "for i, j in itertools.product(range(10), range(2)):\n",
    "    \n",
    "    station = stations[i]\n",
    "    series = target[station]\n",
    "    series = series[series.between(0,100)]\n",
    "    \n",
    "    if j == 0:\n",
    "        series.plot.hist(bins = 50, ax = axs[i][j])\n",
    "        axs[i][j].set_title(f\"{station} \\n No filter\")\n",
    "    else:\n",
    "        series_mask = series.copy().mask(series < treshold, 0)\n",
    "        series_mask.plot.hist(bins = 50, ax = axs[i][j])\n",
    "        axs[i][j].set_title(f\"{station} \\n Treshold : {treshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff763a93",
   "metadata": {},
   "source": [
    "It seems like the treshold of 5 is borderline for small satation, but good for big stations. I'm wondering if most of this small transactions happen before 6 am, or after 10 pm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a775c30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of transactions by station\n",
    "fig, axs = plt.subplots(10, sharey = False, figsize = (15,60))\n",
    "for i in range(10):\n",
    "    \n",
    "    station = stations[i]\n",
    "    series = target[station]\n",
    "    \n",
    "    df = pd.DataFrame({'hour':series.index.hour + series.index.minute/60, 'value':series.values})\n",
    "    g = sns.boxplot(x='hour', y='value', data=df, ax = axs[i])\n",
    "    axs[i].tick_params(axis='x', rotation=90)\n",
    "    axs[i].set_title(station)\n",
    "    axs[i].set_xlabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc41b264",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of transactions by station\n",
    "fig, axs = plt.subplots(10, sharey = False, figsize = (15,60))\n",
    "for i in range(10):\n",
    "    \n",
    "    station = stations[i]\n",
    "    series = target[station]\n",
    "    series = series[series.between(0,20)]\n",
    "    \n",
    "    df = pd.DataFrame({'hour':series.index.hour + series.index.minute/60, 'value':series.values})\n",
    "    sns.boxplot(data = df, x = 'hour', y = 'value', ax = axs[i])\n",
    "    axs[i].tick_params(axis='x', rotation=90)\n",
    "    axs[i].set_title(station)\n",
    "    axs[i].set_xlabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ec0af",
   "metadata": {},
   "source": [
    "5 seems to be a resonale treshold for most stations. I will use this treshold to infer that a station was close. \n",
    "\n",
    "For that I will modify the input itself, because I want to avoid comparing a zero value with some prediction, which would increase the error by a lot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataFrame, so I keep both versions \n",
    "target = data.clean_data('../../data/transactions.parquet')\n",
    "# target.iloc[:,:-8] = target.iloc[:,:-8].mask(target.iloc[:,:-8] <= 5, 0)\n",
    "# target.to_parquet('../../data/transactions_closures_infered.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65a2ca",
   "metadata": {},
   "source": [
    "# Reducing the lookback window \n",
    "\n",
    "Remove the 8th to 10th hour look back window. This could be useful for the fully defiened transformer, but no really for the GNN + Transformer. \n",
    "\n",
    "The 8th and 10th tries to look at shifted spatio-temporal correlations (This could be another research problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b012b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for simulation \n",
    "transactions_path = '../../data/transactions.parquet'\n",
    "stations_path = '../../data/stations_DB.parquet'\n",
    "adj_path = '../../data/adjacency_matrix.parquet'\n",
    "aggregation = \"15-mins\"\n",
    "# train_date = '2018-08-01'\n",
    "train_date = '2015-08-20'\n",
    "max_transactions = '1500'\n",
    "max_stations = None\n",
    "\n",
    "train_data, test_data, adj_matrix, metadata = data.tf_data(\n",
    "        transactions_path,\n",
    "        stations_path,\n",
    "        adj_path,\n",
    "        aggregation,\n",
    "        train_date,\n",
    "        max_transactions,\n",
    "        max_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75e2bb7",
   "metadata": {},
   "source": [
    "# Including function to get data for a ranges of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.clean_data('../../data/transactions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ee3953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train features shape: (1062, 10, 147)\n",
      "Test features shape: (154, 10, 147)\n",
      "\n",
      "Train time_embeddings shape: (1062, 11, 8)\n",
      "Test time_embeddings shape: (154, 11, 8)\n",
      "\n",
      "Train spatial_embeddings shape: (1062, 147, 2)\n",
      "Test spatial_embeddings shape: (154, 147, 2)\n",
      "\n",
      "Train labels shape: (1062, 147)\n",
      "Test labels shape: (154, 147)\n",
      "\n",
      "Train status shape: (1062, 11, 147)\n",
      "Test status shape: (154, 11, 147)\n",
      "\n",
      "Adj Matrix Shape: (1, 147, 10, 147)\n"
     ]
    }
   ],
   "source": [
    "#Prepare data for simulation \n",
    "transactions_path = '../../data/transactions.parquet'\n",
    "stations_path = '../../data/stations_DB.parquet'\n",
    "adj_path = '../../data/adjacency_matrix.parquet'\n",
    "aggregation = \"15-mins\"\n",
    "# train_date = '2018-08-01'\n",
    "train_date = '2018-08-29'\n",
    "max_transactions = None\n",
    "max_stations = None\n",
    "date_range = [\"2018-08-01\",'2018-08-30'] #New piece of information. \n",
    "\n",
    "train_data, test_data, adj_matrix, metadata = data.tf_data(\n",
    "        transactions_path,\n",
    "        stations_path,\n",
    "        adj_path,\n",
    "        aggregation,\n",
    "        train_date,\n",
    "        max_transactions,\n",
    "        max_stations,\n",
    "        date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ecbaac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-08-15 04:00:00', '2018-08-15 04:15:00',\n",
       "               '2018-08-15 04:30:00', '2018-08-15 04:45:00',\n",
       "               '2018-08-15 05:00:00', '2018-08-15 05:15:00',\n",
       "               '2018-08-15 05:30:00', '2018-08-15 05:45:00',\n",
       "               '2018-08-15 06:00:00', '2018-08-15 06:15:00',\n",
       "               ...\n",
       "               '2018-08-28 20:00:00', '2018-08-28 20:15:00',\n",
       "               '2018-08-28 20:30:00', '2018-08-28 20:45:00',\n",
       "               '2018-08-28 21:00:00', '2018-08-28 21:15:00',\n",
       "               '2018-08-28 21:30:00', '2018-08-28 21:45:00',\n",
       "               '2018-08-28 22:00:00', '2018-08-28 22:15:00'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=1062, freq=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['train_date_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa4de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-08-28 22:30:00', '2018-08-28 22:45:00',\n",
       "               '2018-08-29 04:00:00', '2018-08-29 04:15:00',\n",
       "               '2018-08-29 04:30:00', '2018-08-29 04:45:00',\n",
       "               '2018-08-29 05:00:00', '2018-08-29 05:15:00',\n",
       "               '2018-08-29 05:30:00', '2018-08-29 05:45:00',\n",
       "               ...\n",
       "               '2018-08-30 20:30:00', '2018-08-30 20:45:00',\n",
       "               '2018-08-30 21:00:00', '2018-08-30 21:15:00',\n",
       "               '2018-08-30 21:30:00', '2018-08-30 21:45:00',\n",
       "               '2018-08-30 22:00:00', '2018-08-30 22:15:00',\n",
       "               '2018-08-30 22:30:00', '2018-08-30 22:45:00'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=154, freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['test_date_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8340796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
