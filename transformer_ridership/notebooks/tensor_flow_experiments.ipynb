{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86ecb7e-5de8-43ac-8068-d12ab232a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "np.set_printoptions(suppress=True)\n",
    "from data import tf_data, read_stations\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, MultiHeadAttention, LayerNormalization\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bdf965-c4be-4a5e-b0e9-c310091e6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 16)\n",
      "(None, 1, 8, 4)\n"
     ]
    }
   ],
   "source": [
    "layer = MultiHeadAttention(num_heads=1, key_dim=2)\n",
    "target = tf.keras.Input(shape=[8, 16])\n",
    "source = tf.keras.Input(shape=[4, 16])\n",
    "output_tensor, weights = layer(target, source,\n",
    "                               return_attention_scores=True)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "print(weights.shape)\n",
    "# layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "456f837c-8fa4-4e24-bb05-e3e82be8cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 147, 10)\n",
      "(None, 1, 1, 147, 18, 147)\n"
     ]
    }
   ],
   "source": [
    "layer = MultiHeadAttention(num_heads=1, key_dim=64)\n",
    "target = tf.keras.Input(shape=[1, 147, 10])\n",
    "source = tf.keras.Input(shape=[18, 147, 10])\n",
    "output_tensor, weights = layer(target, source,\n",
    "                               return_attention_scores=True)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91afdb4f-0cf0-4c4a-bb79-03556d3460da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d940e30b-4303-419e-8abb-be1213ff4141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (8206, 18, 147)\n",
      "Test features shape: (730, 18, 147)\n",
      "\n",
      "Train time_embeddings shape: (8206, 19, 8)\n",
      "Test time_embeddings shape: (730, 19, 8)\n",
      "\n",
      "Train spatial_embeddings shape: (8206, 147, 2)\n",
      "Test spatial_embeddings shape: (730, 147, 2)\n",
      "\n",
      "Train labels shape: (8206, 147)\n",
      "Test labels shape: (730, 147)\n",
      "\n",
      "(8206,)\n",
      "(730,)\n"
     ]
    }
   ],
   "source": [
    "transactions_path = '../data/clean_transactions.csv'\n",
    "stations_path = '../data/clean_stations_database_v2.csv'\n",
    "aggregation = \"15-mins\"\n",
    "max_stations = None\n",
    "max_transactions = 10000\n",
    "train_date = '2015-12-01'\n",
    "\n",
    "train_data, test_data, metadata = tf_data(\n",
    "        transactions_path,\n",
    "        stations_path,\n",
    "        aggregation,\n",
    "        train_date,\n",
    "        max_transactions,\n",
    "        max_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f85f0e-c98a-4355-8ab3-61b32eb44b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=float64, numpy=\n",
       "array([  0.,   0.,   0.,   0., 242., 215., 212., 172., 221., 295., 250.,\n",
       "       205.,  80.,  83., 128.,  72.,  54.,  24.])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['features'][0,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b7d76e-f19c-4a5a-9654-681449f13503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['labels'][0,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc721217-fe66-43d2-a871-3c0f4784cafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['features', 'time_embeddings', 'spatial_embeddings', 'labels'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73055ec3-e195-42e9-93aa-b61ce62697b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=float64, numpy=\n",
       "array([[-0.67638112, -0.73655181,  0.93087375, -0.36534102,  0.8660254 ,\n",
       "         0.5       ,  0.        ,  1.        ]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['time_embeddings'][0,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ecee3ec-8b76-4cbd-811b-4e8959daace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(730, 147, 2), dtype=float64, numpy=\n",
       "array([[[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]],\n",
       "\n",
       "       [[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]],\n",
       "\n",
       "       [[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]],\n",
       "\n",
       "       [[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]],\n",
       "\n",
       "       [[-4.40028658, -4.84577421],\n",
       "        [-4.78932063, -4.95052437],\n",
       "        [-4.08125421, -4.77791487],\n",
       "        ...,\n",
       "        [ 2.06380647, -3.18630475],\n",
       "        [ 2.00396156, -3.45237508],\n",
       "        [ 2.2462913 ,  3.51326342]]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['spatial_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03785b3d-21a7-45e6-8c04-b30802f91eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMax(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, min_value = None, max_value = None, range_values = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.min_x = min_value\n",
    "        self.max_x = max_value\n",
    "        self.min_t = 0\n",
    "        self.max_t = 1\n",
    "        \n",
    "        if range_values: \n",
    "            self.min_t = range_values[0]\n",
    "            self.max_t = range_values[1]\n",
    "        \n",
    "    def adapt(self, data):\n",
    "        self.min_x = tf.math.reduce_min(data).numpy()\n",
    "        self.max_x = tf.math.reduce_max(data).numpy()\n",
    "\n",
    "    def call(self, x, reverse = False):\n",
    "        \n",
    "        #Raise error is min and max are none. \n",
    "        if reverse: \n",
    "            x = (((x - self.min_t)*(self.max_x - self.min_x))/(self.max_t - self.min_t)) \n",
    "            x = x + self.min_x\n",
    "        else: \n",
    "            x = (x - self.min_x)/(self.max_x - self.min_x)\n",
    "            x = x * (self.max_t - self.min_t) + self.min_t #Range values\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e4ea273-801a-44bb-b198-a0d2f31819a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_layer = MinMax(range_values = (0,1))\n",
    "minmax_layer.adapt((train_data['features']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7517babf-69df-46e1-a5d5-61d325c41ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = minmax_layer(train_data['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f890a0a1-99ce-44fb-89ed-8471ab34c2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=float32, numpy=\n",
       "array([0.12934545, 0.10162856, 0.6974632 , 0.32821798, 0.18321328,\n",
       "       0.1807078 , 0.16630128, 0.18665831, 0.17945506, 0.19245224,\n",
       "       0.16708425, 0.18383965, 0.04635139, 0.05261509, 0.07422487,\n",
       "       0.06482931, 0.08001879, 0.07720012], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[89,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c238f6d5-9d2a-400c-97d3-0303b08a12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=float32, numpy=\n",
       "array([ 826.     ,  649.     , 4454.     , 2096.     , 1170.     ,\n",
       "       1154.     , 1062.     , 1192.     , 1146.     , 1229.     ,\n",
       "       1067.     , 1174.     ,  296.     ,  336.     ,  474.     ,\n",
       "        414.     ,  510.99997,  492.99997], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_layer(r[89,:,0], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c7c35b6-54e8-4a23-ba4e-28433de7595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_layer.min_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aff49bcc-77cc-4f92-b7a3-539130bf569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6386.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_layer.max_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6372820-483c-41f9-82a0-203ce63e9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSpaceEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.concat = tf.keras.layers.Concatenate(axis = 3)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        window_size = input_shape[0][1]\n",
    "        num_station = input_shape[1][1]\n",
    "\n",
    "        self.t_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.RepeatVector(num_station),\n",
    "            tf.keras.layers.Reshape(target_shape = (num_station,window_size,8)),\n",
    "            tf.keras.layers.Permute(dims = (2,1,3))\n",
    "        ])\n",
    "\n",
    "        self.s_embedding =  tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.RepeatVector(window_size),\n",
    "            tf.keras.layers.Reshape(target_shape = (window_size,num_station,2)),\n",
    "            # tf.keras.layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        time_embeddings, spatial_embeddings = inputs\n",
    "\n",
    "        time_embeddings = self.t_embedding(time_embeddings)\n",
    "        spatial_embeddings = self.s_embedding(spatial_embeddings)\n",
    "        embeddings = self.concat([time_embeddings, spatial_embeddings])\n",
    "        return embeddings\n",
    "        # return time_embeddings, spatial_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a19328e-ca86-4be9-836c-739ec6f85ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Time Space Embedding shape: (100, 18, 147, 10)\n",
      "Decoder Time Space Embedding shape: (100, 1, 147, 10)\n"
     ]
    }
   ],
   "source": [
    "layer_ts_1 = TimeSpaceEmbedding()\n",
    "out_1 = layer_ts_1([train_data['time_embeddings'][:100,:-1],train_data['spatial_embeddings'][:100]])\n",
    "print('Encoder Time Space Embedding shape: {}'.format(out_1.shape))\n",
    "\n",
    "layer_ts_2 = TimeSpaceEmbedding()\n",
    "out_2 = layer_ts_2([train_data['time_embeddings'][:100,-1:],train_data['spatial_embeddings'][:100]])\n",
    "print('Decoder Time Space Embedding shape: {}'.format(out_2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c60bbfcd-c69a-4021-8370-24fd1f710fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_all(out_1[0,0,:,:8] == out_1[0,0,:,:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916f465c-fa9f-4d08-9e3c-a443ff9f8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, normalizer, d_model = 10):\n",
    "        super().__init__()\n",
    "        self.norm = normalizer\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Dense(d_model)\n",
    "        self.ts_embedding = TimeSpaceEmbedding()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, time_embeddings, spatial_embeddings = inputs\n",
    "        x = self.norm(x) # Shape (batch_size, seq_length)\n",
    "        x = x[:,:,:,tf.newaxis]\n",
    "        x = self.embedding(x) #Shape (batch_size, seq_length, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        e = self.ts_embedding([time_embeddings, spatial_embeddings])\n",
    "        # x = x + e\n",
    "        x = self.add([x, e])\n",
    "        return x #Shape (batch_size, seq_length, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1950945a-ae34-4c05-9df8-c3236689a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = tf.keras.layers.Normalization(axis = None, mean = 188.4318877714359, variance = 120971.63484231419)\n",
    "# unnorm = tf.keras.layers.Normalization(axis = None, mean = 188.4318877714359, variance = 120971.63484231419, invert = True)\n",
    "# norm.adapt(train_data['features'][:100])\n",
    "\n",
    "# unnorm = tf.keras.layers.Normalization(axis = None, invert = True)\n",
    "# unnorm.adapt(train_data['features'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1889152-9d8e-41a9-9ca4-1b62f3bbd63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Shape + Embeddings + Positional Embeddigns: (100, 18, 147, 10)\n"
     ]
    }
   ],
   "source": [
    "norm = tf.keras.layers.Normalization(axis = None, mean = 188.4318877714359, variance = 120971.63484231419) # Normalize All\n",
    "# norm = tf.keras.layers.Normalization(axis = -1) #Normalize station by station\n",
    "# norm.adapt(train_data['features'][:100])\n",
    "\n",
    "layer_pos = PositionalEmbedding(norm,\n",
    "                                d_model = 10) \n",
    "out_3 = layer_pos([train_data['features'][:100], \n",
    "                   train_data['time_embeddings'][:100,:-1],\n",
    "                   train_data['spatial_embeddings'][:100]\n",
    "                  ])\n",
    "\n",
    "print('Model Input Shape + Embeddings + Positional Embeddigns: {}'.format(out_3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2978bc11-4f59-40d3-99b5-cbf581e1da7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=28.405294>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_max(out_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1c2d18-8c69-4b05-8bc8-f29d8a0d24dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-32.153503>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_min(out_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ebfa94-14cf-499e-a6ab-ddef12b10366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'positional_embedding/dense/kernel:0' shape=(1, 10) dtype=float32, numpy=\n",
       " array([[-0.1638875 ,  0.66872746, -0.03148836,  0.07698011,  0.09612834,\n",
       "         -0.09473622, -0.06342274, -0.16402102, -0.71561295,  0.5829312 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'positional_embedding/dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_pos.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5df2c8cc-5653-45d2-b8d2-306c3694ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x, \n",
    "            return_attention_scores=True)\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "        \n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class CausalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask = True)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x\n",
    "\n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(dff, activation='relu'),\n",
    "          tf.keras.layers.Dense(d_model),\n",
    "          tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.add([x, self.seq(x)])\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads, key_dim, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attention_temporal = GlobalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            attention_axes = (1)\n",
    "            )\n",
    "\n",
    "        self.self_attention_spatial = GlobalSelfAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=d_model,\n",
    "            dropout=dropout_rate,\n",
    "            attention_axes = (2))\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attention_temporal(x)\n",
    "        x = self.self_attention_spatial(x)\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2901851e-6b0d-4758-b1a0-e36666dd09f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Context shape: (100, 18, 147, 10)\n",
      "Temportal Attention Scores shape: (100, 147, 1, 18, 18)\n",
      "Spatial Attention Scores shape: (100, 18, 1, 147, 147)\n",
      "Max Attention Temporal: 0.1889762282371521\n",
      "Max Attention Temporal: 0.012486708350479603\n"
     ]
    }
   ],
   "source": [
    "layer_encoder = EncoderLayer(d_model = 10, num_heads = 1, key_dim = 64, dff = 2048)\n",
    "encoder_out = layer_encoder(out_3)\n",
    "attention_scores_temporal = layer_encoder.self_attention_temporal.last_attn_scores\n",
    "attention_scores_spatial =layer_encoder.self_attention_spatial.last_attn_scores\n",
    "\n",
    "max_att_temporal = tf.math.reduce_max(attention_scores_temporal)\n",
    "max_att_spatial = tf.math.reduce_max(attention_scores_spatial)\n",
    "print( \"Output Context shape: {}\".format(encoder_out.shape))\n",
    "print( \"Temportal Attention Scores shape: {}\".format(attention_scores_temporal.shape))\n",
    "print( \"Spatial Attention Scores shape: {}\".format(attention_scores_spatial.shape))\n",
    "print('Max Attention Temporal: {}'.format(max_att_temporal))\n",
    "print('Max Attention Temporal: {}'.format(max_att_spatial))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97aa4157-82d8-49f6-bea9-6d996944aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, normalizer, num_layers, d_model, num_heads,\n",
    "               key_dim, dff,  dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.pos_embedding = PositionalEmbedding(\n",
    "            normalizer, d_model=d_model)\n",
    "\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(d_model=d_model,\n",
    "                         num_heads=num_heads,\n",
    "                         key_dim = key_dim,\n",
    "                         dff=dff,\n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # `x` is token-IDs shape: (batch, seq_len)\n",
    "\n",
    "        # `x`has (tokes, and Temporal and Positional Embeddings)\n",
    "        x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "        # Add dropout.\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x)\n",
    "\n",
    "        return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "858932ad-a1e1-4b85-9ff8-4a1aa3e55faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (100, 18, 147, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(normalizer = norm, num_layers = 2, d_model = 10, num_heads = 1, key_dim = 64, dff = 512)\n",
    "out_encoder = encoder([train_data['features'][:100], \n",
    "                       train_data['time_embeddings'][:100,:-1],\n",
    "                       train_data['spatial_embeddings'][:100]\n",
    "                      ])\n",
    "print(\"Encoder output shape: {}\".format(out_encoder.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d73bf270-ab2b-4d2d-bc20-88c2a8cc9149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_encoder[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "500b82da-73c8-42a1-80dc-a72b28ecfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.enc_layers[0].self_attention_temporal.last_attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daa93fbe-ac96-499f-9f17-6911fb666fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               key_dim,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # self.causal_self_attention = CausalSelfAttention(\n",
    "        #     num_heads=num_heads,\n",
    "        #     key_dim=d_model,\n",
    "        #     dropout=dropout_rate)\n",
    "\n",
    "        self.cross_attention = CrossAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            attention_axes = (1,2), \n",
    "            kernel_initializer=tf.keras.initializers.GlorotNormal(), \n",
    "            bias_initializer = 'zeros')\n",
    "\n",
    "        self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, context):\n",
    "#         x = self.causal_self_attention(x=x)\n",
    "        x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "        # Cache the last attention scores for plotting later\n",
    "        self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "        x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3ae905f-934b-4aac-926f-0463f167ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Time Space Embedding shape: (100, 1, 147, 10)\n"
     ]
    }
   ],
   "source": [
    "layer_ts_2 = TimeSpaceEmbedding()\n",
    "out_2 = layer_ts_2([train_data['time_embeddings'][:100,-1:],train_data['spatial_embeddings'][:100]])\n",
    "print('Decoder Time Space Embedding shape: {}'.format(out_2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19295303-ffcc-417d-9b9e-49c5dd3bc99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder layer Output shape: (100, 1, 147, 10)\n",
      "Attention Weights shapes: (100, 1, 1, 147, 18, 147)\n"
     ]
    }
   ],
   "source": [
    "decoder_layer = DecoderLayer(d_model = 10, num_heads = 1, key_dim = 64, dff = 512)\n",
    "decoder_out = decoder_layer(out_2, out_3)\n",
    "print (\"Decoder layer Output shape: {}\".format(decoder_out.shape))\n",
    "print (\"Attention Weights shapes: {}\".format(decoder_layer.last_attn_scores.shape))\n",
    "# decoder_layer.cross_attention.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "036bb68d-c878-4425-9d7a-d0bd951d3eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(147, 10), dtype=float32, numpy=\n",
       "array([[-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "        -4.4002867 , -4.845774  ],\n",
       "       [-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "        -4.7893205 , -4.9505243 ],\n",
       "       [-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "        -4.081254  , -4.777915  ],\n",
       "       ...,\n",
       "       [-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "         2.0638065 , -3.1863048 ],\n",
       "       [-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "         2.0039616 , -3.4523752 ],\n",
       "       [-0.6763811 , -0.7365518 ,  0.93087375, ...,  1.        ,\n",
       "         2.2462914 ,  3.5132635 ]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_2[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90665c1e-0cbb-49fc-894d-ba1abc036f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.558229744\n",
      "0.258420646\n",
      "0.164463669\n",
      "0.373072\n",
      "0.390261889\n",
      "0.192642495\n",
      "0.292528063\n",
      "0.306967586\n",
      "1.4892633\n",
      "1.29142845\n"
     ]
    }
   ],
   "source": [
    "# Variability in the Encoder (It seems very small) \n",
    "# Target STD > 0.03\n",
    "for i in range(10):\n",
    "    tf.print(tf.math.reduce_std(decoder_out[88,0,:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea2dc0c-2c74-4dd6-bd61-72f21221e770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18, 5), dtype=float32, numpy=\n",
       "array([[0.00038065, 0.00035971, 0.00035763, 0.00035702, 0.00035854],\n",
       "       [0.00042175, 0.00036087, 0.00035878, 0.00035816, 0.00035833],\n",
       "       [0.00060641, 0.0003719 , 0.00039881, 0.00036911, 0.00037456],\n",
       "       [0.00058758, 0.00037266, 0.00039662, 0.00037462, 0.0003755 ],\n",
       "       [0.00065847, 0.00035173, 0.00040206, 0.00035795, 0.0003686 ],\n",
       "       [0.00062614, 0.00035116, 0.00039296, 0.00035788, 0.00036645],\n",
       "       [0.00059631, 0.00035063, 0.0003841 , 0.00035785, 0.0003678 ],\n",
       "       [0.000608  , 0.00035014, 0.00038849, 0.00035955, 0.00037078],\n",
       "       [0.00068119, 0.00034969, 0.00038726, 0.00036233, 0.00037083],\n",
       "       [0.00065637, 0.00034928, 0.00039308, 0.00036432, 0.00036882],\n",
       "       [0.00062836, 0.00034892, 0.00038349, 0.00036342, 0.00037459],\n",
       "       [0.00073178, 0.0003486 , 0.00039623, 0.00036602, 0.00037674],\n",
       "       [0.00038287, 0.00035706, 0.00035904, 0.0003564 , 0.00035471],\n",
       "       [0.00036044, 0.00036154, 0.00035944, 0.00035882, 0.00035797],\n",
       "       [0.00036067, 0.00036176, 0.00035967, 0.00035905, 0.0003582 ],\n",
       "       [0.00036496, 0.00036194, 0.00035985, 0.00035923, 0.00035838],\n",
       "       [0.00039175, 0.00036207, 0.00036305, 0.00035952, 0.00035884],\n",
       "       [0.0004295 , 0.00036215, 0.00036554, 0.00035977, 0.00036028]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_layer.last_attn_scores[5,0,0,0,:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aef86dc3-68ef-4c94-9668-66cc6a8e9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, *, num_layers, d_model, num_heads, key_dim, \n",
    "                 dff, dropout_rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.ts_embeddings = TimeSpaceEmbedding()\n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(d_model=d_model, num_heads=num_heads, \n",
    "                         key_dim = key_dim, dff=dff, \n",
    "                         dropout_rate=dropout_rate)\n",
    "            for _ in range(num_layers)]\n",
    "\n",
    "        self.last_attn_scores = None\n",
    "\n",
    "    def call(self, time_info, space_info, context):\n",
    "\n",
    "        x = self.ts_embeddings([time_info, space_info])\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x  = self.dec_layers[i](x, context)\n",
    "\n",
    "        self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bdd74f7-78e5-4512-ac96-521b802418f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(num_layers = 1, \n",
    "                  d_model = 10, \n",
    "                  num_heads = 1, \n",
    "                  key_dim = 64, \n",
    "                  dff = 256)\n",
    "decoder_output = decoder(\n",
    "    time_info = train_data['time_embeddings'][:100,-1:],\n",
    "    space_info = train_data['spatial_embeddings'][:100],\n",
    "    context = out_encoder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca067f74-f4bb-4715-a011-775c2d29f083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 147, 10), dtype=float32, numpy=\n",
       "array([[[-1.3587011 , -1.2561235 ,  0.7062563 , ...,  1.2659124 ,\n",
       "          0.30370155, -0.71928406],\n",
       "        [-1.4011933 , -1.7639025 ,  1.3213884 , ...,  1.0465951 ,\n",
       "          0.38347372, -0.6001412 ],\n",
       "        [-1.5314049 , -1.5713661 ,  1.0516503 , ...,  1.1190933 ,\n",
       "          0.33989525, -0.5602668 ],\n",
       "        ...,\n",
       "        [-1.4828482 , -1.6350299 ,  1.142728  , ...,  1.133483  ,\n",
       "          0.34282243, -0.656931  ],\n",
       "        [-1.3851902 , -1.2816969 ,  0.80154413, ...,  1.2626746 ,\n",
       "          0.29927102, -0.666968  ],\n",
       "        [-1.3979375 , -1.7624282 ,  1.3258314 , ...,  1.0478123 ,\n",
       "          0.36454266, -0.6042946 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26013895-88bf-48eb-9a7e-3c66c944462b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(147, 10), dtype=float32, numpy=\n",
       "array([[ 0.58125377,  0.17522734,  0.7806701 , ...,  2.437379  ,\n",
       "         1.0234131 , -2.9449162 ],\n",
       "       [-1.0602976 , -1.4350901 ,  0.70752794, ...,  0.22954649,\n",
       "         0.18265942,  0.4411723 ],\n",
       "       [-1.0602976 , -1.4350901 ,  0.70752794, ...,  0.22954649,\n",
       "         0.18097934,  0.4411443 ],\n",
       "       ...,\n",
       "       [-1.0602976 , -1.4350901 ,  0.70752794, ...,  0.22954649,\n",
       "         0.16639832,  0.44088632],\n",
       "       [ 0.7037004 ,  0.2953443 ,  0.78612596, ...,  2.6020658 ,\n",
       "         1.0709995 , -3.1977165 ],\n",
       "       [-1.0602976 , -1.4350901 ,  0.70752794, ...,  0.22954649,\n",
       "         0.16596532,  0.43980032]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_3[40,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b9b912e6-9b0f-48e5-bc37-4be4f5ac8ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_29/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[ 0.47699338],\n",
       "        [-0.3378294 ],\n",
       "        [ 0.52709764],\n",
       "        [ 0.46894234],\n",
       "        [ 0.2024687 ],\n",
       "        [-0.54486436],\n",
       "        [-0.46729538],\n",
       "        [-0.23314953],\n",
       "        [ 0.13476223],\n",
       "        [ 0.66441625]], dtype=float32)>,\n",
       " <tf.Variable 'dense_29/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f669a3cc-6119-4d4f-ab05-ce81ade9c19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 1, 147, 1), dtype=float32, numpy=\n",
       "array([[[[-1.7301033],\n",
       "         [-1.8509916],\n",
       "         [-1.9397391],\n",
       "         ...,\n",
       "         [-1.8448691],\n",
       "         [-1.7311057],\n",
       "         [-1.8390683]]],\n",
       "\n",
       "\n",
       "       [[[-1.6963948],\n",
       "         [-1.832441 ],\n",
       "         [-1.8977286],\n",
       "         ...,\n",
       "         [-1.8330915],\n",
       "         [-1.7028039],\n",
       "         [-1.8207558]]],\n",
       "\n",
       "\n",
       "       [[[-1.6562171],\n",
       "         [-1.8077337],\n",
       "         [-1.8491088],\n",
       "         ...,\n",
       "         [-1.8153813],\n",
       "         [-1.6776092],\n",
       "         [-1.7959186]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.708894 ],\n",
       "         [-2.2060375],\n",
       "         [-2.115303 ],\n",
       "         ...,\n",
       "         [-2.0606067],\n",
       "         [-2.0396852],\n",
       "         [-2.1928253]]],\n",
       "\n",
       "\n",
       "       [[[-1.6821105],\n",
       "         [-2.1748266],\n",
       "         [-2.0945687],\n",
       "         ...,\n",
       "         [-2.052512 ],\n",
       "         [-2.0231206],\n",
       "         [-2.1615899]]],\n",
       "\n",
       "\n",
       "       [[[-1.6524347],\n",
       "         [-2.1427932],\n",
       "         [-2.0745325],\n",
       "         ...,\n",
       "         [-2.0447097],\n",
       "         [-1.9863095],\n",
       "         [-2.1295104]]]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goal: Prediction has variability \n",
    "f = tf.keras.layers.Dense(1)\n",
    "final_results = f(decoder_output)\n",
    "final_results#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "52d9a902-b19d-4f1b-ade1-d86eb1ccee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.nn.softmax(final_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe459d17-d122-4c76-87ff-5d18806866d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(a[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3fa001d0-524b-4de1-b1a1-e0132418f73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 9000), dtype=float32, numpy=\n",
       "array([[0.00011923, 0.00011405, 0.00011329, ..., 0.00011233, 0.00010616,\n",
       "        0.00011123],\n",
       "       [0.00011774, 0.0001128 , 0.00011329, ..., 0.00011146, 0.00010581,\n",
       "        0.00011192]], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fcdee-31e5-48aa-9ec3-f746b869709e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
